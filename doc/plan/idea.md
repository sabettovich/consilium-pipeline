# Архитектура FastAPI-приложения для юридического конвейера
## Слои приложения (Clean Architecture)

Приложение следует принципам Clean Architecture с чётким разделением на слои. Доменная логика (бизнес-правила) отделена от инфраструктуры и фреймворка, что упрощает поддержку и масштабирование
github.com
. Основные слои архитектуры могут быть следующими:

Доменный слой (Entities & Use Cases): Здесь определяются основные сущности и бизнес-логика юридического конвейера. Например, сущность Document (документ) с атрибутами (тип, содержимое, результаты обработки), а также Use Cases – случаи использования или сервисы для каждого этапа конвейера. Можно выделить сервисы: DocumentProcessingService (общая оркестрация обработки документа), OCRService для распознавания текста, ASRService для распознавания речи, ClassificationService для классификации/извлечения данных, DocumentGenerationService для формирования итоговых документов, и AIAnalysisService для вызова моделей GPT. Доменный слой объявляет интерфейсы для взаимодействия с внешними системами (репозитории, сервисы OCR/ASR, API OpenAI) – это границы домена. Например, интерфейс TextRecognizerInterface, SpeechRecognizerInterface, AIClientInterface, DocumentRepositoryInterface и т.д.

Слой случаев использования (Application/Boundary): Иногда его объединяют с доменным. Это уровень, через который внешние компоненты обращаются к домену. Здесь реализуется последовательность шагов обработки юридических документов. Например, use-case «обработать документ» будет оркестратором: принимать загруженный документ, вызывать поочередно OCR/ASR, затем классификатор, затем генератор отчёта. Этот оркестратор пользуется интерфейсами, определёнными в домене, не зная деталей их реализации (например, как именно выполнено OCR). Такой подход соответствует инверсии зависимостей
github.com
: высокоуровневый код (бизнес-логика) определяет интерфейсы, а низкоуровневый код их реализует.

Инфраструктурный слой (Infrastructure/Gateways): Содержит реализации интерфейсов домена. Здесь находятся адаптеры для конкретных технологий: реализация DocumentRepository (например, на базе SQLAlchemy или файловой системы), реализация TextRecognizer через OCR-движок (например, Tesseract или Azure Computer Vision), реализация SpeechRecognizer через внешнее API (Google Speech-to-Text, Vosk и т.п.), клиент для OpenAI API (реализация AIClientInterface, использующая библиотеку OpenAI для GPT). Также здесь могут быть классы для формирования документов (например, генерация DOCX/PDF из шаблона через библиотеку). Этот слой соответствует Gateways в шаблоне репозитория: он скрывает детали хранилищ и внешних сервисов за унифицированными интерфейсами
febus982.github.io
febus982.github.io
.

Слой презентации и фреймворков: Это внешний слой, включающий FastAPI для HTTP API (веб-интерфейс) и фоновые задачи Dramatiq. FastAPI обрабатывает входящие запросы, например, загрузку документа через REST API. Контроллер (маршрут FastAPI) не содержит бизнес-логики – он валидирует запрос, сохраняет файл (например, временно в хранилище через репозиторий документов) и вызывает соответствующий use-case из домена (например, DocumentProcessingService.process(document_id)). Запрос может сразу возвращать ответ (например, 202 Accepted с ID задачи), а тяжелая обработка происходит асинхронно. Dramatiq worker – это отдельный процесс/контейнер, выполняющий фоновые задачи. Он вызывает методы доменного слоя (use-cases) через сериализованные сообщения. В Clean Architecture задачи Dramatiq считаются частью слоя драйверов, они могут вызывать граничные сервисы домена
febus982.github.io
febus982.github.io
. Таким образом, HTTP-контроллер или задача Dramatiq обращается к доменному сервису, передает необходимые данные (например, файл или его ID) и запускает обработку.

Такое структурирование обеспечивает слабо связанную систему. Доменный код не зависит от деталей FastAPI, Dramatiq или конкретных OCR/AI библиотек – их внедрение происходит через интерфейсы (Inversion of Control)
github.com
. Например, можно легко заменить механизм OCR (локальный Tesseract на облачный Vision API) изменив лишь реализацию TextRecognizerInterface в инфраструктуре, не затрагивая остальной код.

Очередь задач с Dramatiq: очереди, приоритеты и воркеры

Для долгих операций конвейера используется очередь задач Dramatiq
febus982.github.io
. Dramatiq позволяет определять фоновые актеры (tasks), которые выполняются воркерами параллельно, читая сообщения из брокера (Redis, RabbitMQ и т.д.). Предложенная архитектура может задействовать несколько очередей Dramatiq для разных типов задач, чтобы изолировать тяжелые этапы и задать приоритеты:

Очередь OCR: задачи распознавания текста из изображения/скана. OCR может быть ресурсоемким (CPU/GPU), поэтому выделяется отдельная очередь "ocr_queue" с воркерами, настроенными, например, на использование тессеракта или другого движка. Если OCR сильно нагружает CPU, этих воркеров можно запустить с ограниченным числом потоков или на отдельных узлах.

Очередь ASR: задачи распознавания речи из аудио. Аналогично, "asr_queue" с отдельными воркерами. Распознавание аудио (ASR) может требовать много CPU или даже GPU (для нейросетевых моделей), поэтому имеет смысл отделить эти задачи. Можно выделить больше воркеров или более мощные машины для этой очереди, особенно если обрабатываются большие аудиофайлы (WAV, MP3).

Очередь AI/GPT: если использование OpenAI (GPT) осуществляется асинхронно (через API-вызовы), такие задачи, как сложная классификация или генерация текста с помощью GPT, можно отправлять в отдельную очередь, например "ai_queue". Эти задачи зависят от внешнего API и могут ждать сеть, поэтому воркеры можно настроить иначе (например, больше воркеров, но они в основном ожидают ответа API).

Очередь генерации документов: Финальный шаг – сборка итогового документа из шаблона – обычно менее тяжелый (форматирование текста, вставка данных). Это можно выполнять либо на общей очереди по умолчанию, либо на отдельной "generation_queue". Такие задачи могут выполняться быстро, поэтому нет необходимости в больших задержках.

Очередь по умолчанию (default): для прочих легковесных задач или оркестрации. Например, можно иметь задачу-оркестратор, которая последовательностью вызывает другие шаги (ниже об оркестрации). Если оркестрация быстрых решений (например, определить тип файла и поставить другие задачи) – это можно делать и на default-очереди.

Приоритеты. Dramatiq не поддерживает приоритет сообщений напрямую, но разделение на разные очереди фактически позволяет приоритизировать ресурсы. Например, если OCR и ASR задачи самые тяжелые, можно запускать меньше их одновременно. Также можно реализовать логику приоритета на уровне приложения: например, если приходит критичный документ, поместить его задачи в отдельную высокоприоритетную очередь/воркер. Еще один подход – завести две очереди для одной задачи (например, ocr_high и ocr_low) и вручную направлять задания, но это увеличивает сложность. Проще масштабировать числом воркеров: Dramatiq позволяет запустить несколько процессов-воркеров; каждый процесс может иметь пул потоков (по умолчанию, например 8 потоков на процесс) или использовать gevent для I/O-bound задач
dramatiq.io
. Для CPU-bound (OCR/ASR) лучше оставить потоки.

Воркеры. Приложение запускается как минимум в двух режимах: (1) HTTP-сервер FastAPI для приёма запросов, (2) один или несколько процессов dramatiq-worker для обработки очередей
febus982.github.io
. Можно запускать несколько экземпляров воркеров на разных серверах для горизонтального масштабирования – все они слушают один брокер. Каждый воркер при старте объявляет, какие очереди он обслуживает. Например, можно настроить один набор воркеров обслуживать только ocr_queue (с целью не мешать другим), другой – только asr_queue, а часть воркеров – универсальные (обслуживают default и generation). Такое распределение позволяет тонко настроить использование ресурсов.

Оркестрация задач. Юридический конвейер имеет несколько последовательных этапов, поэтому нужно продумать, как увязать задачи. Есть два подхода:

Chain (цепочка) / Pipeline: Dramatiq поддерживает последовательный запуск задач через pipeline и параллельный через group
dramatiq.io
. Например, можно реализовать единый пайплайн: сначала задача OCR, затем задача классификации, затем генерация отчёта – всё это как последовательная цепочка Dramatiq. Если один документ требует выполнения всех шагов, можно отправить pipeline из актеров: pipeline( ocr.message(doc_id), classify.message(doc_id), generate.message(doc_id) ). Dramatiq обеспечит выполнение их по очереди для данного сообщения. Аналогично, если нужен параллелизм (скажем, документ содержит и картинки, и аудио, и их можно распознавать одновременно), можно воспользоваться group для параллельного выполнения и затем объединить результаты.

Задача-оркестратор: Альтернативный способ – запускать одну фоновую задачу process_document на default-очереди, которая в своём коде последовательно вызывает нужные сервисы (OCR, ASR, и т.д.) синхронно или дополнительными саб-задачами. Например, воркер получает сообщение “обработать документ 123” и внутри функции actor делает:

вызов OCRService (выполнится синхронно внутри воркера, возможно, вызывая внешнюю библиотеку или HTTP API),

вызов ASRService (если есть аудио),

затем ClassificationService (может быть локально или вызов OpenAI),

и генерацию документа.

Такой подход проще в реализации (все шаги в одном контексте), но если некоторые шаги очень долгие, воркер будет занят одним документом длительное время. Зато не нужно передавать результаты через брокер. Можно также комбинировать: оркестратор может запускать отдельные задачи и ждать их завершения (например, с помощью Future или polling результата из хранилища). Для более сложных зависимостей существует библиотека dramatiq-workflow, которая позволяет строить вложенные цепочки и группы задач
dramatiq.io
, однако можно обойтись и без неё, если конвейер линеен.

В контексте юридического конвейера, вероятно, будет достаточно линейной последовательности для каждого документа. Значит, можно применить pipeline Dramatiq. Например, при загрузке нового документа API эндпоинт создаёт запись документа в БД (статус "в очереди") и отправляет цепочку задач: OCR -> классификация -> генерация отчёта. Каждая задача знает ID документа, берет необходимые данные из БД/хранилища, обновляет статус по завершении (например, OCR завершён, текст сохранён; классификация завершена, данные извлечены и сохранены; и т.д.). Итоговая задача генерации отмечает документ как "готов" и может сохранить или отправить сгенерированный документ клиенту.

Обработка ошибок и повторов: Dramatiq поддерживает автоматическое логирование ошибок и количество попыток выполнения задачи. При исключении в задаче можно настроить retries. Например, если OCR-сервис временно недоступен, задача ocr_task может автоматически повториться N раз. Также можно реализовать отложенные задачи (delay) если нужно, или Dead Letter Queue для неуспешных документов. Благодаря Clean Architecture, каждая задача строго решает свою часть и при сбоях не повреждает общий состояние документа (т.к. промежуточные результаты сохраняются в репозиторий). Это повышает надёжность конвейера.

## Мониторинг и Observability (OpenTelemetry, Prometheus)

Для такого критичного приложения необходимо обеспечить мониторинг, трассировку и логирование. Репозиторий-шаблон уже включает интеграцию OpenTelemetry
febus982.github.io
, что означает, что мы можем собирать метрики, логи и трассы (спанс) единообразно.

Трассировка (Traces): Каждый запрос FastAPI и каждая фоновая задача Dramatiq могут порождать span-ы OpenTelemetry. С помощью контекста OTEL можно связать цепочку: например, запрос загрузки документа инициирует background-задачу – благодаря передаче контекста (например, через Trace ID, который можно передать в сообщение Dramatiq), можно связать последующие шаги обработки с исходным запросом. В системе трассировки (Jaeger, Zipkin или другой, совместимый с OTLP) можно будет наблюдать целиком прохождение документа через конвейер, включая время каждого этапа. Это облегчает отладку и анализ производительности (например, видно, что OCR занял 5 секунд, GPT-классификация 2 секунды и т.п.).

Метрики (Prometheus): Dramatiq имеет встроенную поддержку метрик Prometheus. Если запускать воркер через CLI dramatiq или настроить PrometheusMiddleware, процесс-воркер будет экспортировать метрики на порт (по умолчанию 9191)
dramatiq.io
. К основным метрикам относятся:

dramatiq_messages_total – счетчик выполненных задач,

dramatiq_message_duration_milliseconds – гистограмма времени выполнения задач,

dramatiq_message_errors_total – количество ошибок в задачах,

... и другие (все метрики помечаются лейблами очереди и имени актёра)
dramatiq.io
.

Prometheus будет опрашивать эти метрики, а затем на их основе можно построить дашборды. Существует готовый Grafana-дэшборд для Dramatiq
dramatiq.io
, который отображает количество задач, время выполнения, количество ошибок и т.д. – это даёт обзор здоровья фоновой очереди. Кроме того, можно собирать и собственные метрики приложения: например, число загруженных документов, распределение типов файлов, размеры файлов, и метрики из самих сервисов (если внешние – возможно ограничено, но например, можно считать количество запросов к OpenAI API, среднее время OCR и прочее).

Логирование: Используемый стек OpenTelemetry позволяет централизованно собирать логи. В каждом компоненте (FastAPI, задачи) настроен логгер, который пишет в консоль или файл, а OTEL-агент может пересылать логи в систему типа Elastic (ELK) или Grafana Loki. Для отладки приложения разработчики могут просматривать логи воркеров Dramatiq (либо в stdout, либо в агрегированном хранилище). Также стоит настроить уведомления об ошибках – например, интегрировать Sentry для автоматического сбора исключений из FastAPI и задач, чтобы быстро реагировать на сбои в обработке конкретных документов.

Алерты: Поверх метрик Prometheus можно настроить alerting. Например, сигнализировать, если очередь задач растёт (задачи не успевают обрабатываться), или если доля ошибок увеличивается. Это важно для надёжности: сразу увидеть, если, скажем, сервис OCR начал выдавать ошибки (превышен лимит API или упал распознаватель).

Интеграция внешних сервисов: OpenAI, OCR, ASR

Ключевые этапы конвейера – распознавание текста/речи и интеллектуальная обработка – требуют вызова внешних сервисов или библиотек. В архитектуре Clean Architecture интеграция делается через слой инфраструктуры (gateways) и вызывается из домена через интерфейсы. Вот как можно встроить эти функции:

OCR (Optical Character Recognition): Распознавание текста в образах (PDF, сканы, изображения). В домене определяется интерфейс TextRecognitionService с методом, например, extract_text(document) -> str. Инфраструктурная реализация может использовать локальную библиотеку (Tesseract через pytesseract) или внешнее API (Google Vision, ABBYY Cloud OCR SDK и т.п.). Выбор реализации прозрачен для домена. Задача Dramatiq ocr_task будет вызывать этот сервис: например, text = text_recognition_service.extract_text(file_path). Полученный текст сохраняется в репозиторий (в базу или файл) для дальнейших шагов. OCR-вызов может быть долгим (несколько секунд на страницу), но он внутри фоновой задачи, поэтому не блокирует основной поток приложения.

ASR (Automatic Speech Recognition): Распознавание речи из аудио (WAV, MP3). Аналогично, интерфейс домена SpeechRecognitionService с методом transcribe(audio_file) -> str. Реализация может быть на базе сервисов облака (Google Speech-to-Text, Amazon Transcribe, Yandex SpeechKit для русского, Whisper API от OpenAI, etc.) или локальной моделью (например, Vosk, Coqui STT, либо тот же Whisper оффлайн). Фоновая задача asr_task вызывает этот сервис, получает транскрибированный текст речи. Далее этот текст можно прикрепить к документу как расшифровка аудио (в репозитории).

Классификация и извлечение данных: После получения сырого текста (из документа, из OCR или ASR) надо выделить нужные данные и классифицировать документ. Здесь возможны разные подходы. Можно реализовать в домене сервис DocumentAnalysisService со способом analyze(text) -> ExtractedData. ExtractedData – это, например, структура: тип документа (класс), ключевые поля (имя клиента, сумма, даты и т.д. – в зависимости от юр. задачи). Реализация этого сервиса может использовать комбинацию правил/регулярных выражений, традиционных ML-моделей или вызывать OpenAI GPT для более сложной обработки на естественном языке. Например, можно задать промпт модели GPT: "Выдели из текста договора имена сторон, дату, сумму" – и распарсить ответ. В Clean Architecture мы можем инкапсулировать вызов OpenAI API в отдельный класс, реализующий интерфейс AIClientInterface или непосредственно внутри DocumentAnalysisService. Однако лучше разделить: пусть AIClient отвечает за низкоуровневый вызов GPT (отправка запроса, получение ответа), а DocumentAnalysisService решает, использовать ли GPT или нет, и обрабатывает результат. Таким образом, если в будущем решим отказаться от OpenAI в пользу локальной модели, поменяем только AIClient. Задача Dramatiq classify_task будет выполнять extracted = analysis_service.analyze(text), где внутри произойдёт нужная логика (GPT или иная). Важно предусмотреть, что GPT-вызов – сетевой и может занять время, поэтому функция должна быть асинхронной или выполнена в отдельном потоке. Dramatiq позволяет писать актёры как синхронные или асинхронные (c await), поддерживая оба режима.

Генерация итоговых документов: Когда нужные данные извлечены, конвейер формирует результат – например, отчёт или заполненный шаблон договора. Сервис домена DocumentGenerationService может принимать ExtractedData и, например, на основе шаблона (DOCX/ODT) подставлять данные, получая новый документ. Это можно сделать библиотеками вроде docxtpl (для DOCX), Jinja2 (для текстовых шаблонов), отчетами Jasper или же даже с помощью GPT (если нужен связный человеческий текст по данным). Но зачастую юридические документы строго шаблонные, поэтому можно хранить шаблоны и заполнять поля. Фоновая задача generate_document_task берёт результаты анализа и генерирует файл (DOCX/PDF). Итог сохраняется через репозиторий (например, в базу как файл BLOB или в облачное хранилище, а в БД только ссылка). Можно также здесь же вызвать OpenAI, если нужно сгенерировать пояснения или краткое резюме к документу (GPT справляется с задачей реферирования). Однако эти вызовы должны быть чётко контролируемы (с учётом стоимости и времени).

OpenAI-агенты (GPT): Помимо использования GPT как описано выше (для классификации или генерации текста внутри конкретного шага), можно предусмотреть отдельный этап, где AI-агент выполняет сложную задачу. Например, после получения всех данных можно попросить агента оценить документ на предмет рисков, или составить сопроводительное письмо. Этот шестой этап может быть оформлен как отдельный actor ai_agent_task, который использует уже собранные данные и вызывает серию подсказок (prompt) у GPT. Архитектурно, это также будет реализовано через сервис домена (например, LegalAIService), чтобы изолировать детали работы с агентами (контекстная память, функции). Задачу можно встроить в общий pipeline (например, после генерации документа вызвать ещё GPT для объяснений) либо сделать опциональной по запросу.

Интеграция всех этих сервисов требует внимания к временным задержкам и отказам. Каждый вызов OCR/ASR/OpenAI – потенциально долгий и ненадёжный. Поэтому, оборачиваем их в задачи Dramatiq (как мы сделали) и обрабатываем ошибки. Например, если GPT API не отвечает, можно заложить повтор или альтернативный путь (правила вместо AI). Если OCR не смог прочитать, можно отправить задачу на ручную проверку (это выходит за рамки, но архитектура должна допускать расширение – например, добавлением нового actor для ручной обработки какого-то шага).

## Dashboard для мониторинга очередей и задач

Для мониторинга и администрирования конвейера требуется веб-дашборд, где видны статусы задач, очереди, время выполнения, ошибки. Есть несколько вариантов реализации Dashboard:

Grafana + Prometheus (метрики): Как упомянуто, Dramatiq предоставляет метрики, и на их основе можно настроить дашборд в Grafana
dramatiq.io
. Grafana позволит видеть графики: число выполняемых задач, длительность, размер очередей. Однако Grafana – это скорее обзор системы, чем детальный трекинг каждой задачи. Для бизнес-операторов может потребоваться видеть конкретные документы в обработке, их статус.

Dramatiq Dashboard (WSGI middleware): Существует экспериментальный проект dramatiq_dashboard от автора Dramatiq
github.com
. Это веб-интерфейс, написанный как WSGI-middleware, который можно подключить к приложению. Он работает пока только с брокером Redis и показывает очереди, задачи и их состояние. Подключается очень просто (несколько строчек кода, указывающих broker и путь приложения)
github.com
. Если наш брокер – Redis, можно встроить этот Dashboard прямо в наше FastAPI приложение (через Starlette’s WSGI middleware support) или запустить отдельно. На Dashboard будет отображаться список очередей, количество сообщений, возможно последние сообщения. Однако этот проект очень ранний и может быть нестабилен, но для внутренних нужд может подойти.

Flower (для Celery): Не подходит напрямую, так как мы используем Dramatiq. Flower используется как пример популярного решения для Celery, эквивалентом для Dramatiq является либо упомянутый dramatiq_dashboard, либо собственная реализация.

Собственный админ-панель: Поскольку у нас уже есть FastAPI с фронтендом (Swagger/Redoc) и, возможно, какой-то фронт для пользователей, мы можем реализовать страничку Dashboard самостоятельно. Например, сделать endpoint /admin/tasks или полноценный небольшой frontend-приложение (React/Vue), которое через API получает данные о задачах и отображает. Откуда брать данные? Можно сохранять статусы задач в базу данных: при начале обработки документа – отмечать его статус ("OCR in progress", "ASR done", "Failed at classification" и т.п.). Эти статусы меняет сам workflow, обновляя запись документа. Тогда Dashboard просто делает запросы к API: получить список документов в работе, их стадии, ошибки. Для оперативности можно использовать WebSocket (в шаблоне есть Socket.IO поддержка
febus982.github.io
) – каждый воркер при завершении шага шлёт сообщение по WebSocket, и Dashboard обновляется в реальном времени. Такой кастомный подход даст наиболее детализированную информацию для операторов: вплоть до текста ошибок или просматривать результаты OCR прямо в UI.

Логирование и трейсинг в Dashboard: Можно также включить в Dashboard просмотр логов или трасс. Например, интегрировать с Jaeger UI (для трасс) или Kibana (для логов). Но, скорее всего, достаточно ссылок, т.к. DevOps/админы будут пользоваться этими инструментами отдельно. Для бизнес-пользователей – достаточно видеть статус и результат.

С учётом существующих инструментов, оптимальным решением будет комбо: использовать Grafana для системных метрик (нагрузка, производительность конвейера) и кастомный веб-интерфейс/расширение для отображения статусов конкретных документов. Если выбор падает на dramatiq_dashboard (WSGI), это минимальный путь получить что-то похожее на Flower, но нужно учесть его сырой статус. Возможно, сообщество Dramatiq предложит в будущем более зрелый мониторинг, но пока можно внедрить basic-решение.

## Масштабируемость и поддерживаемость решения

Предложенная архитектура ориентирована на масштабируемость по нагрузке и удобство поддержки:

Горизонтальная масштабируемость: Благодаря использованию очередей и разделению сервисов, можно масштабировать компоненты независимо. Если растёт число загрузок документов, можно запустить больше экземпляров FastAPI (за балансировщиком). Если узким местом стал OCR – увеличиваем число воркеров ocr_queue или выделяем отдельный мощный сервер/контейнер для них. Все воркеры подключены к одному брокеру, что позволяет добавлять/удалять обработчики динамически. Компоненты без состояния (stateless) – FastAPI и воркеры – хорошо ложатся на контейнеризацию (Docker/Kubernetes). В K8s можно автоскейлить воркеры по длине очередей (метрики dramatiq_messages_inprogress показывают занятость
dramatiq.io
). Отдельно, если нужен GPU для распознавания или для некоторых AI-моделей, можно поднять специализированный воркер с GPU и на уровне роутинга задач направлять соответствующие задачи к нему (например, разным именем очереди).

Надёжность и отказоустойчивость: Использование брокера и фоновых задач обеспечивает, что при падении отдельного воркера задачи не потеряются – они вернутся в очередь или попадут в Dead Letter (в зависимости от настроек). Dramatiq при корректной настройке брокера гарантирует доставку сообщений хотя бы однократно. Кроме того, Clean Architecture делает возможным тестирование бизнес-логики вне инфраструктуры. Можно писать unit-тесты на сервисы (OCRService, DocumentService) с моками интерфейсов, что повышает доверие к коду. Для отказоустойчивости, можно запустить брокер в кластерном режиме (Redis Cluster или RabbitMQ mirrored queues) – это предотвращает потерю сообщений при сбое брокера. База данных (если используется для хранения документов/статусов) тоже должна быть отказоустойчивой (репликация, резервное копирование).

Удобство поддержки (Maintainability): Разделение на слои означает, что команды разработчиков могут работать параллельно над разными частями. Например, специалисты по ML могут улучшать ClassificationService или GPT-промпты, не затрагивая веб-часть. Фронтенд-разработчики могут менять Dashboard или API контракт, не влазя в логику OCR. Чистая архитектура упрощает замену компонентов: решили использовать другой OCR – достаточно написать новый Gateway-адаптер и внедрить через DI. Высокое покрытие тестами (шаблон поощряет TDD, например, есть интеграция с CI) позволит вносить изменения с уверенностью.

Наблюдаемость и отладка: Встроенный мониторинг (OTel + Prometheus) упрощает поддержку на продакшене. Если какой-то этап стал узким местом, метрики это покажут (например, среднее время OCR резко выросло). Трассировки помогут локализовать проблемы (скажем, задержка не в самом OCR, а в ожидании ответа от GPT). Логи, собранные централизованно, позволят быстро найти, где произошла ошибка в конвейере для конкретного документа.

Расширяемость: Потребности юридического конвейера могут расти – добавить новые форматы (например, видео -> тогда добавить сервис видео-распознавания кадров, новый шаг), новые типы итоговых документов, интеграции с другими системами (CRM, базы данных). Благодаря модульности, новые домены или сервисы можно добавлять, не ломая существующий код. Например, можно выделить отдельный домен для "LegalCase", куда стекаются результаты по нескольким документам, или добавить событийную шину (шаблон уже готов к CloudEvents/Knative
febus982.github.io
). Это решение выступает скелетом, наращивать функциональность на котором достаточно удобно.

Вывод: Используя репозиторий-шаблон Bootstrap Python FastAPI как основу, мы получаем современное, хорошо структурированное приложение. Оно сочетает FastAPI для синхронных действий (удобный REST API) с Dramatiq для асинхронной обработки, все это оплетено принципами Clean Architecture (чистый код, разделение обязанностей) и дополнено OpenTelemetry для наблюдаемости. Такая архитектура соответствует требованиям юридического конвейера: каждый документ обрабатывается надёжно через серию этапов, система масштабируется под нагрузку, а разработчики и администраторы имеют все инструменты для поддержки и развития решения.

## Источники:

Репозиторий Bootstrap Python FastAPI (Clean Architecture шаблон)
github.com
febus982.github.io

Документация Dramatiq (очереди, pipeline/group, Prometheus метрики)
dramatiq.io
dramatiq.io

Проект dramatiq_dashboard (Web Dashboard для задач Dramatiq)
github.com
github.com